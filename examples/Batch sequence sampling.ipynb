{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import gym\n",
    "import os\n",
    "\n",
    "from spacelib.dataset import RecurrentReplayBuffer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import roboschool\n",
    "# env = gym.make('RoboschoolHalfCheetah-v1')\n",
    "# observation_space = env.observation_space\n",
    "# action_space = env.action_space\n",
    "\n",
    "import minerl\n",
    "minerl_env_name = 'MineRLObtainDiamondDense-v0'\n",
    "observation_space = gym.envs.registration.spec(minerl_env_name)._kwargs['observation_space']\n",
    "action_space = gym.envs.registration.spec(minerl_env_name)._kwargs['action_space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files in /tmp/spacelibevxyuyd4\n",
      "\n",
      " /tmp/spacelibevxyuyd4/lumh20aDjh\n",
      "  .../1.0.0.dat: 2916 KB\n",
      "  .../0.0.0.dat: 75 KB\n",
      "\n",
      " /tmp/spacelibevxyuyd4/JikHOX9e9c\n",
      "  .../1.0.0.dat: 15108 KB\n",
      "  .../0.0.0.dat: 393 KB\n",
      "\n",
      " /tmp/spacelibevxyuyd4/T7NZ5NNibR\n",
      "  .../1.0.0.dat: 1584 KB\n",
      "  .../0.0.0.dat: 41 KB\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 3\n",
    "workdir = tempfile.mkdtemp(prefix='spacelib')\n",
    "print(f\"Saving files in {workdir}\")\n",
    "\n",
    "replay_buffer = RecurrentReplayBuffer(observation_space, action_space, data_root=workdir)\n",
    "\n",
    "for n_ep in range(n_episodes):\n",
    "\n",
    "#     obs = env.reset()\n",
    "    obs = observation_space.sample()\n",
    "    \n",
    "    done = False\n",
    "    replay_buffer.begin_episode()\n",
    "    episode_length = 0\n",
    "    \n",
    "    while not done:\n",
    "\n",
    "        act = action_space.sample()\n",
    "        \n",
    "#         new_obs, rew, done, _ = env.step(act)\n",
    "        new_obs = observation_space.sample()\n",
    "        rew = episode_length\n",
    "        done = episode_length > 100 and np.random.randn()<-3\n",
    "        \n",
    "        replay_buffer.append((obs, act, rew, done))\n",
    "        \n",
    "        obs = new_obs\n",
    "        episode_length += 1\n",
    "        \n",
    "    replay_buffer.end_episode()\n",
    "    \n",
    "for path, dirs, files in os.walk(workdir):\n",
    "    if any(f.endswith('.dat') for f in files):\n",
    "        print('\\n',path)\n",
    "        for datfile in files:\n",
    "            size_kb = os.path.getsize(os.path.join(path, datfile))//1024\n",
    "            print(f\"  .../{datfile}: {size_kb} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.2 ms ± 852 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "replay_buffer.sample_sequence(length=64, batch_size=32, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.9 ms ± 2.69 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "replay_buffer.sample_sequence(length=256, batch_size=8, device=torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 64, 64, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacelib.flatter import Flatter\n",
    "sample_sequence_batch = replay_buffer.sample_sequence(length = 64, batch_size=32, device=torch.device('cuda'))\n",
    "Flatter(observation_space).unflatten(sample_sequence_batch.obs)['pov'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   4.,    5.,    6.,  ...,   65.,   66.,   67.],\n",
       "        [ 149.,  150.,  151.,  ...,  210.,  211.,  212.],\n",
       "        [   7.,    8.,    9.,  ...,   68.,   69.,   70.],\n",
       "        ...,\n",
       "        [ 355.,  356.,  357.,  ...,  416.,  417.,  418.],\n",
       "        [ 790.,  791.,  792.,  ...,  851.,  852.,  853.],\n",
       "        [1191., 1192., 1193.,  ..., 1252., 1253., 1254.]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the above made-up example, the reward increments at each time step. \n",
    "# As a simple sanity check, we can verify that this holds in sampled sequences.\n",
    "sample_sequence_batch.rew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minecraft",
   "language": "python",
   "name": "minecraft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
